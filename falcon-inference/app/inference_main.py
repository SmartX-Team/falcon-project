
import os
import json
import logging
import signal
import threading
import base64
import time
from datetime import datetime, timezone 

import cv2
import numpy as np
import torch
from ultralytics import YOLO
import onnxruntime as ort
from kafka import KafkaConsumer, KafkaProducer
from kafka.errors import KafkaError
import math

# --- ë¡œê¹… ì„¤ì • ---
LOG_LEVEL = os.environ.get('LOG_LEVEL', 'INFO').upper()
logging.basicConfig(
    level=LOG_LEVEL,
    format='%(asctime)s - %(levelname)s - %(name)s - [%(threadName)s] - %(message)s'
)
logger = logging.getLogger(__name__)

# --- í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì„¤ì •ê°’ ë¡œë“œ ---
KAFKA_BROKER_LIST = os.environ.get('KAFKA_BROKER_LIST', '10.79.1.1:9094').split(',')
INPUT_TOPIC = os.environ.get('INPUT_TOPIC', 'fused_input_for_inference') 
OUTPUT_TOPIC_INFERENCE = os.environ.get('OUTPUT_TOPIC_INFERENCE', 'inference_results') 
GROUP_ID = os.environ.get('GROUP_ID', 'falcon-inference-group')

MODEL_DIR = os.environ.get('MODEL_DIR', '/models')
YOLO_MODEL_PATH = os.path.join(MODEL_DIR, 'yolov5s.pt') 
UNIDEPTH_MODEL_PATH = os.path.join(MODEL_DIR, 'unidepth_v2-384x384.onnx') 

ORT_PROVIDERS = ['CUDAExecutionProvider', 'CPUExecutionProvider']

X_CORRECTION_LEFT_THRESHOLD = float(os.environ.get('X_CORRECTION_LEFT_THRESHOLD', 384.0))
X_CORRECTION_RIGHT_THRESHOLD = float(os.environ.get('X_CORRECTION_RIGHT_THRESHOLD', 1536.0))
X_CORRECTION_OFFSET = float(os.environ.get('X_CORRECTION_OFFSET', 1.0)) 
DEPTH_OFFSET_FACTOR = float(os.environ.get('DEPTH_OFFSET_FACTOR', -1.0)) 

CAMERA_YAW_DEGREES = float(os.environ.get('CAMERA_YAW_DEGREES', 0.0))  # ì¹´ë©”ë¼ Yawê° (degree)
CAMERA_DEGREE_RESERVED = float(os.environ.get('CAMERA_DEGREE_RESERVED', 0.0))  # í–¥í›„ í™•ì¥ìš©

# ë³´ì • ê³„ìˆ˜ ì¶”ê°€
DEPTH_SCALING_FACTOR = float(os.environ.get('DEPTH_SCALING_FACTOR', 0.9))  # ê¹Šì´ê°’ ìŠ¤ì¼€ì¼ë§
LATERAL_SCALING_FACTOR = float(os.environ.get('LATERAL_SCALING_FACTOR', 0.3))  # ì¢Œìš° ì˜¤í”„ì…‹ ìŠ¤ì¼€ì¼ë§

CAMERA_HORIZONTAL_FOV_DEGREES = float(os.environ.get('CAMERA_HORIZONTAL_FOV_DEGREES', 77.0))  # ìˆ˜í‰ FOV (degree)
CAMERA_VERTICAL_FOV_DEGREES = float(os.environ.get('CAMERA_VERTICAL_FOV_DEGREES', 45.0))    # ìˆ˜ì§ FOV (degree, ì„ íƒì‚¬í•­)

# UWB ê³µê°„ ì¢Œí‘œê³„ ì •ì˜ í˜¹ì‹œ ì´í›„ì— ë³€ê²½ë˜ë©´ ì ë‹¹íˆ ìˆ˜ì •
UWB_SPACE_X_MIN = float(os.environ.get('UWB_SPACE_X_MIN', 5.4))     # ì™¼ìª½ ê²½ê³„
UWB_SPACE_X_MAX = float(os.environ.get('UWB_SPACE_X_MAX', 34.29))   # ì˜¤ë¥¸ìª½ ê²½ê³„  
UWB_SPACE_Y_MIN = float(os.environ.get('UWB_SPACE_Y_MIN', 7.29))    # ìœ„ìª½(ë¶ìª½) ê²½ê³„
UWB_SPACE_Y_MAX = float(os.environ.get('UWB_SPACE_Y_MAX', 34.0))    # ì•„ë˜ìª½(ë‚¨ìª½) ê²½ê³„

# í™˜ê²½ë³€ìˆ˜ ì¶”ê°€ (ê¸°ì¡´ í™˜ê²½ë³€ìˆ˜ ì„¹ì…˜ì— ì¶”ê°€)
INFERENCE_MAX_FPS = float(os.environ.get('INFERENCE_MAX_FPS', '3.0'))  # ê¸°ë³¸ê°’: ì´ˆë‹¹ 2í”„ë ˆì„
INFERENCE_SKIP_STRATEGY = os.environ.get('INFERENCE_SKIP_STRATEGY', 'DROP_OLD').upper()  # DROP_OLD ë˜ëŠ” THROTTLE

# ì „ì—­ ë³€ìˆ˜ ì¶”ê°€ (ê¸°ì¡´ ì „ì—­ ë³€ìˆ˜ ì„¹ì…˜ì— ì¶”ê°€)
last_inference_time_by_camera = {}  # ì¹´ë©”ë¼ë³„ ë§ˆì§€ë§‰ ì¸í¼ëŸ°ìŠ¤ ì‹œê°„ ì¶”ì 
inference_interval = 1.0 / INFERENCE_MAX_FPS if INFERENCE_MAX_FPS > 0 else 0
message_consume_count = 0  # ì†Œë¹„í•œ ë©”ì‹œì§€ ìˆ˜ (ë””ë²„ê¹…ìš©)
inference_perform_count = 0  # ì‹¤ì œ ìˆ˜í–‰í•œ ì¸í¼ëŸ°ìŠ¤ ìˆ˜ (ë””ë²„ê¹…ìš©)
# --- ì „ì—­ ë³€ìˆ˜ ---
stop_event = threading.Event()
yolo_model = None
unidepth_session = None
# kafka_producerëŠ” consume_messages í•¨ìˆ˜ ë‚´ì—ì„œ ì§€ì—­ ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ê³ , í•„ìš”ì‹œ í´ë˜ìŠ¤ ë©¤ë²„ ë“±ìœ¼ë¡œ ë³€ê²½ ê°€ëŠ¥
# ì—¬ê¸°ì„œëŠ” consume_messages í•¨ìˆ˜ ë‚´ì—ì„œë§Œ ì‚¬ìš©ë˜ë„ë¡ ìˆ˜ì •
KAFKA_PRODUCER_ACKS_ENV = os.environ.get("KAFKA_PRODUCER_ACKS", "1")
if KAFKA_PRODUCER_ACKS_ENV.lower() == 'all':
    KAFKA_ACKS_CONFIG = 'all'
else:
    try:
        KAFKA_ACKS_CONFIG = int(KAFKA_PRODUCER_ACKS_ENV)
    except ValueError:
        logger.warning(f"Invalid KAFKA_PRODUCER_ACKS value '{KAFKA_PRODUCER_ACKS_ENV}'. Defaulting to 1.")
        KAFKA_ACKS_CONFIG = 1
KAFKA_RETRIES_CONFIG = int(os.environ.get("KAFKA_PRODUCER_RETRIES", "5"))



def should_process_inference(camera_id, current_time):
    """
    ì¸í¼ëŸ°ìŠ¤ë¥¼ ìˆ˜í–‰í• ì§€ ê²°ì •í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        camera_id: ì¹´ë©”ë¼ ID
        current_time: í˜„ì¬ ì‹œê°„ (time.monotonic())
    
    Returns:
        bool: ì¸í¼ëŸ°ìŠ¤ë¥¼ ìˆ˜í–‰í• ì§€ ì—¬ë¶€
    """
    global last_inference_time_by_camera
    
    if INFERENCE_MAX_FPS <= 0:
        return True  # ì œí•œ ì—†ìŒ
    
    last_time = last_inference_time_by_camera.get(camera_id, 0)
    time_elapsed = current_time - last_time
    
    if time_elapsed >= inference_interval:
        last_inference_time_by_camera[camera_id] = current_time
        return True
    else:
        return False


def calculate_position_with_yaw_and_fov(base_uwb_x, base_uwb_y, depth_value, cx, cy, image_width, image_height, yaw_degrees, horizontal_fov_degrees):
    """
    ì¹´ë©”ë¼ì˜ Yawì¶•ì„ ê³ ë ¤í•˜ì—¬ ì‹¤ì œ ì›”ë“œ ì¢Œí‘œë¥¼ ê³„ì‚°

    UWB ì¢Œí‘œê³„ íŠ¹ì„±:
    - X: 5.4(ì„œìª½) ~ 34.29(ë™ìª½)
    - Y: 7.29(ë¶ìª½) ~ 34.0(ë‚¨ìª½) - Yê°’ì´ ì‘ì„ìˆ˜ë¡ ë¶ìª½

    # UWB ì¢Œí‘œê³„ì— ë§ì¶˜ Yaw ê°ë„ ë³€í™˜
    # 0ë„ = ë¶ìª½(Y ê°ì†Œ ë°©í–¥), 90ë„ = ë™ìª½(X ì¦ê°€ ë°©í–¥)
    # 180ë„ = ë‚¨ìª½(Y ì¦ê°€ ë°©í–¥), 270ë„ = ì„œìª½(X ê°ì†Œ ë°©í–¥)

    Args:
        base_uwb_x, base_uwb_y: UWBë¡œë¶€í„° ì–»ì€ ì¹´ë©”ë¼ ìœ„ì¹˜
        depth_value: ê¹Šì´ ê°’ (ë¯¸í„°)
        cx: ì´ë¯¸ì§€ ë‚´ ê°ì²´ì˜ X ì¤‘ì‹¬ ì¢Œí‘œ
        image_width: ì´ë¯¸ì§€ ì „ì²´ ë„ˆë¹„
        yaw_degrees: ì¹´ë©”ë¼ Yaw ê°ë„ (ë„ ë‹¨ìœ„)
        horizontal_fov_degrees: ì¹´ë©”ë¼ ìˆ˜í‰ FOV (ë„ ë‹¨ìœ„)
    
    Returns:
        tuple: (calculated_x, calculated_y)


    """

    # ê¹Šì´ê°’ ë³´ì • ì ìš©
    corrected_depth = depth_value * DEPTH_SCALING_FACTOR

    # Yawë¥¼ ë¼ë””ì•ˆìœ¼ë¡œ ë³€í™˜
    yaw_rad = math.radians(yaw_degrees)
    horizontal_fov_rad = math.radians(horizontal_fov_degrees)

     # ì´ë¯¸ì§€ ì¤‘ì‹¬ìœ¼ë¡œë¶€í„°ì˜ í”½ì…€ ì˜¤í”„ì…‹ ê³„ì‚°
    center_x = image_width / 2
    center_y = image_height / 2
    pixel_offset_x = cx - center_x
    pixel_offset_y = cy - center_y
    
    # FOVë¥¼ ì‚¬ìš©í•˜ì—¬ í”½ì…€ ì˜¤í”„ì…‹ì„ ì‹¤ì œ ê°ë„ë¡œ ë³€í™˜
    # ìˆ˜í‰ ê°ë„: ì´ë¯¸ì§€ ê°€ì¥ìë¦¬ì—ì„œ FOVì˜ ì ˆë°˜ë§Œí¼ ë²—ì–´ë‚¨
    angle_per_pixel_horizontal = horizontal_fov_rad / image_width
    horizontal_angle_offset = pixel_offset_x * angle_per_pixel_horizontal   
    # ì´ë¯¸ì§€ ì¤‘ì‹¬ ê¸°ì¤€ìœ¼ë¡œ ê°ì²´ì˜ ìƒëŒ€ì  ìœ„ì¹˜ ê³„ì‚° (-1 ~ 1 ë²”ìœ„)
    # cxê°€ ì´ë¯¸ì§€ ì¤‘ì•™ì´ë©´ 0, ì™¼ìª½ ëì´ë©´ -1, ì˜¤ë¥¸ìª½ ëì´ë©´ 1
    relative_x = (cx - image_width / 2) / (image_width / 2)
    
    # ì¹´ë©”ë¼ ì‹œì•¼ê°ì„ ê³ ë ¤í•œ ì‹¤ì œ ê°ë„ ì˜¤í”„ì…‹ ê³„ì‚°
    # ì‹¤ì œ ë¬¼ë¦¬ì  ì˜¤í”„ì…‹ ê³„ì‚° (ì‚¼ê°ë²• ì‚¬ìš©) + ìŠ¤ì¼€ì¼ë§ ì ìš©
    lateral_distance_raw = corrected_depth * math.tan(horizontal_angle_offset)
    lateral_distance = lateral_distance_raw * LATERAL_SCALING_FACTOR
    
    # Yaw ê°ë„ë¥¼ ê³ ë ¤í•˜ì—¬ ì›”ë“œ ì¢Œí‘œê³„ë¡œ ë³€í™˜
    # ì¹´ë©”ë¼ê°€ ë¶ìª½(Y+)ì„ í–¥í•˜ê³  ìˆë‹¤ë©´ yaw=0
    # ì‹œê³„ë°©í–¥ìœ¼ë¡œ íšŒì „ì‹œ yaw ì¦ê°€
    world_x_offset = lateral_distance  * math.cos(yaw_rad + math.pi/2) + corrected_depth * math.cos(yaw_rad)
    world_y_offset = lateral_distance  * math.sin(yaw_rad + math.pi/2) + corrected_depth * math.sin(yaw_rad)
    
    calculated_x = float(base_uwb_x) + world_x_offset
    calculated_y = float(base_uwb_y) + world_y_offset

    angle_from_center_degrees = math.degrees(horizontal_angle_offset)
    
    # UWB ê³µê°„ ê²½ê³„ ì²´í¬ ë° ê²½ê³ 
    if not (UWB_SPACE_X_MIN <= calculated_x <= UWB_SPACE_X_MAX):
        logger.warning(f"Calculated X coordinate ({calculated_x:.2f}) is outside UWB space bounds "
                      f"[{UWB_SPACE_X_MIN} ~ {UWB_SPACE_X_MAX}]")
    
    if not (UWB_SPACE_Y_MIN <= calculated_y <= UWB_SPACE_Y_MAX):
        logger.warning(f"Calculated Y coordinate ({calculated_y:.2f}) is outside UWB space bounds "
                      f"[{UWB_SPACE_Y_MIN} ~ {UWB_SPACE_Y_MAX}]")
    
    return calculated_x, calculated_y, angle_from_center_degrees

# --- ëª¨ë¸ ë¡œë”© í•¨ìˆ˜ --- (ì´ì „ê³¼ ë™ì¼)
def load_yolo_model():
    global yolo_model
    try:
        logger.info(f"Attempting to load YOLOv5 model from: {YOLO_MODEL_PATH}")
        model = YOLO(YOLO_MODEL_PATH)

        if torch.cuda.is_available():
            logger.info("YOLO model will attempt to use GPU.")
            # CUDA ìµœì í™” ì„¤ì •
            #model.model.half()  # FP16 ì‚¬ìš©
            model.model.cuda()
            
        else:
            logger.info("YOLO model will use CPU.")

      
        yolo_model = model
        logger.info(f"YOLOv5 model loaded successfully from {YOLO_MODEL_PATH}")

        # ---í´ë˜ìŠ¤ ì´ë¦„ ë¡œê¹… ì¶”ê°€ ì§€ì  ì‹œì‘ ---
        if yolo_model and hasattr(yolo_model, 'names'):
            logger.info(f"YOLO model class names (ID: Name): {yolo_model.names}")
            if 'person' in yolo_model.names.values():
                logger.info("The 'person' class IS PRESENT in the loaded YOLO model's names.")
            else:
                logger.warning("The 'person' class IS MISSING from the loaded YOLO model's names.")
        else:
            logger.warning("Could not retrieve class names from the loaded YOLO model (model or names attribute not found).")
        # --- í´ë˜ìŠ¤ ì´ë¦„ ë¡œê¹… ì¶”ê°€ ì§€ì  ë ---

    except Exception as e:
        logger.error(f"Error loading YOLOv5 model: {e}", exc_info=True)
        yolo_model = None

def load_unidepth_model():
    global unidepth_session
    try:
        sess_options = ort.SessionOptions()

        #ì„±ëŠ¥ ìµœì í™” ì˜µì…˜ë“¤
        sess_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL

        # ğŸ¯ Provider ìˆœì„œ ìµœì í™” (TensorRT ìš°ì„ ) -> TensorRT ì˜ ë™ì‘í•˜ëŠ”ê±° í™•ì¸í–ˆëŠ”ë°, ëŒ€ì‹  K8S ì—ì„œ ìºì‰¬ ì˜ ì €ì¥í•˜ê³  ë¶ˆëŸ¬ì˜¤ëŠ”ì§€ ì²´í¬ í•„ìš”
        providers = [
            #('TensorrtExecutionProvider', {
            #    'trt_max_workspace_size': 4 * 1024 * 1024 * 1024,  # 4GB
            #    'trt_fp16_enable': True,  # Mixed precision
            #    'trt_engine_cache_enable': True,
            #    'trt_engine_cache_path': '/tmp/trt_cache',
            #    'trt_timing_cache_enable': True,
            #}),            
            ('CUDAExecutionProvider', {
                'device_id': 0,
                'arena_extend_strategy': 'kSameAsRequested',
                'gpu_mem_limit': 8 * 1024 * 1024 * 1024,  # 8GB
                'cudnn_conv_algo_search': 'EXHAUSTIVE',
            }),
            'CPUExecutionProvider'
        ]
        
        unidepth_session = ort.InferenceSession(
            UNIDEPTH_MODEL_PATH, 
            sess_options=sess_options, 
            providers=providers
        )


        logger.info(f"UniDepthV2 ONNX model loaded successfully from {UNIDEPTH_MODEL_PATH} using providers: {unidepth_session.get_providers()}")
        if "CUDAExecutionProvider" not in unidepth_session.get_providers():
            logger.warning("UniDepthV2: CUDAExecutionProvider not available or not used. Check ONNXRuntime-GPU installation and CUDA setup.")
    except Exception as e:
        logger.error(f"Error loading UniDepthV2 ONNX model: {e}", exc_info=True)
        unidepth_session = None

# --- ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ë° ì¶”ë¡  í•¨ìˆ˜ --- (ì´ì „ê³¼ ë™ì¼)
def preprocess_image_for_yolo(image_np):
    return image_np

def preprocess_image_for_unidepth(image_np, target_height=364, target_width=644): # ê¸°ë³¸ê°’ ì‚¬ìš©
    logger.debug(f"Preprocessing image for UniDepth. Original shape: {image_np.shape}, Target HxW: {target_height}x{target_width}")
    img_rgb = cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB)
    
    # ğŸ’¡ cv2.resizeì—ëŠ” (ë„ˆë¹„, ë†’ì´) ìˆœì„œë¡œ ì „ë‹¬
    # ìƒˆë¡œìš´ ë§¤ê°œë³€ìˆ˜ëª…ì„ ì‚¬ìš©í•˜ì—¬ (target_width, target_height) íŠœí”Œì„ ë§Œë“­ë‹ˆë‹¤.
    dsize = (target_width, target_height) 
    img_resized = cv2.resize(img_rgb, dsize, interpolation=cv2.INTER_AREA)
    
    logger.debug(f"Resized image shape for UniDepth: {img_resized.shape}")
    img_normalized = img_resized.astype(np.float32) / 255.0
    img_chw = np.transpose(img_normalized, (2, 0, 1))  # HWC to CHW
    img_nchw = np.expand_dims(img_chw, axis=0)      # Add batch dimension: NCHW
    logger.debug(f"Final preprocessed shape for UniDepth: {img_nchw.shape}")
    return img_nchw

def run_yolo_inference(image_np):
    if yolo_model is None:
        logger.warning("YOLO model is not loaded. Skipping detection.")
        return []
    try:
        results = yolo_model.predict(source=image_np, verbose=False) 
        detections = []
        if results and results[0].boxes:
            logger.info(f"YOLO raw detection count: {len(results[0].boxes)}")
            for box in results[0].boxes:
                xyxy = box.xyxy[0].cpu().numpy().tolist()
                conf = float(box.conf[0].cpu().numpy())
                cls_id = int(box.cls[0].cpu().numpy())
                cls_name = yolo_model.names[cls_id]

                 # 'person' í´ë˜ìŠ¤ì— ëŒ€í•œ ì¶”ê°€ì ì¸ ë¡œê¹…
                if cls_name == 'person':
                    logger.info(f"'person' detected with confidence: {conf:.4f}. Box: {xyxy}")

                detections.append({
                    "box_xyxy": xyxy,
                    "confidence": conf,
                    "class_id": cls_id,
                    "class_name": cls_name
                })
        return detections
    except Exception as e:
        logger.error(f"Error during YOLO inference: {e}", exc_info=True)
        return []

def run_unidepth_inference(image_np_nchw):
    if unidepth_session is None:
        logger.warning("UniDepth model is not loaded. Skipping depth estimation.")
        return None
    try:
        input_name = unidepth_session.get_inputs()[0].name
        #depth_map_onnx = unidepth_session.run(None, {input_name: image_np_nchw})[0]
        outputs     = unidepth_session.run(None, {input_name: image_np_nchw})

        depth_map   = np.squeeze(outputs[1])  
        K_matrix    = outputs[0] 
        logger.debug(f"UniDepth outputs â€” K:{K_matrix.shape}, depth:{depth_map.shape}")
        #depth_map_hw = np.squeeze(depth_map_onnx)
        return depth_map

    except Exception as e:
        logger.error(f"Error during UniDepth inference: {e}", exc_info=True)
        return None

# --- Kafka ì»¨ìŠˆë¨¸ ë° ë©”ì‹œì§€ ì²˜ë¦¬ ---
def consume_messages():
    if not yolo_model or not unidepth_session: 
        logger.error("One or both AI models (YOLO, UniDepth) are not loaded. Cannot start consuming messages.")
        return

    consumer = None # finally ë¸”ë¡ì—ì„œ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ì´ˆê¸°í™”
    kafka_producer_instance = None # finally ë¸”ë¡ì—ì„œ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ì´ˆê¸°í™”

    try: # Main try block for resource management
        # KafkaConsumer ì´ˆê¸°í™”
        try:
            consumer = KafkaConsumer(
                INPUT_TOPIC,
                bootstrap_servers=KAFKA_BROKER_LIST,
                group_id=GROUP_ID,
                auto_offset_reset='latest', 
                consumer_timeout_ms=1000, 
                value_deserializer=lambda v: json.loads(v.decode('utf-8', 'ignore'))
            )
            logger.info(f"Kafka consumer initialized for topic '{INPUT_TOPIC}' with group_id '{GROUP_ID}'.")
        except KafkaError as e:
            logger.error(f"Failed to initialize Kafka consumer: {e}", exc_info=True)
            return # ì»¨ìŠˆë¨¸ ì´ˆê¸°í™” ì‹¤íŒ¨ ì‹œ í•¨ìˆ˜ ì¢…ë£Œ

        # KafkaProducer ì´ˆê¸°í™”
        try:
            kafka_producer_instance = KafkaProducer(
                bootstrap_servers=KAFKA_BROKER_LIST,
                value_serializer=lambda v: json.dumps(v).encode('utf-8'),
                acks=KAFKA_ACKS_CONFIG, 
                retries=KAFKA_RETRIES_CONFIG 
            )
            logger.info(f"Kafka producer initialized for output topic '{OUTPUT_TOPIC_INFERENCE}'.")
        except KafkaError as e:
            logger.error(f"Failed to initialize Kafka producer: {e}", exc_info=True)
            kafka_producer_instance = None # í”„ë¡œë“€ì„œ ì—†ì´ ì§„í–‰ ê°€ëŠ¥í•˜ë„ë¡ ì„¤ì •

        logger.info("Starting message consumption loop...")
        while not stop_event.is_set():
            try: # ë©”ì‹œì§€ í´ë§ ë° ì²˜ë¦¬ë¥¼ ìœ„í•œ ë‚´ë¶€ try ë¸”ë¡
                for message in consumer: # consumer_timeout_ms ë™ì•ˆ ë¸”ë¡
                    if stop_event.is_set():
                        break # ì™¸ë¶€ ì¢…ë£Œ ì‹ í˜¸ ê°ì§€ ì‹œ ë£¨í”„ íƒˆì¶œ
                    current_process_start_time = time.monotonic()
                    logger.debug(f"Received message: {message.topic}, partition={message.partition}, offset={message.offset}")
                    
                    # --- ê°œë³„ ë©”ì‹œì§€ ì²˜ë¦¬ ë¡œì§ ---
                    try: # ê°œë³„ ë©”ì‹œì§€ ì²˜ë¦¬ì— ëŒ€í•œ try-except
                        fused_data = message.value
                        if not isinstance(fused_data, dict):
                            logger.warning(f"Skipping message, not a valid JSON object: Received type: {type(fused_data)}")
                            continue

                        camera_id = fused_data.get("camera_id")
                        image_base64 = fused_data.get("image_data_b64") 
                        original_timestamp_str = fused_data.get("image_timestamp_utc") 
                        uwb_data_from_wrapper = fused_data.get("uwb_data") 
                        # Kafka ë©”ì‹œì§€ì—ì„œ YAW ê°’ ì¶”ì¶œ (ì—†ìœ¼ë©´ í™˜ê²½ë³€ìˆ˜ ê¸°ë³¸ê°’ ì‚¬ìš©)
                        message_yaw_degrees = fused_data.get("camera_yaw_degrees")
                        if message_yaw_degrees is not None:
                            try:
                                effective_yaw_degrees = float(message_yaw_degrees)
                                logger.debug(f"[{camera_id}] Using YAW from message: {effective_yaw_degrees}Â°")
                            except (ValueError, TypeError):
                                effective_yaw_degrees = CAMERA_YAW_DEGREES
                                logger.warning(f"[{camera_id}] Invalid YAW in message ({message_yaw_degrees}). Using default: {CAMERA_YAW_DEGREES}Â°")
                        else:
                            effective_yaw_degrees = CAMERA_YAW_DEGREES
                            logger.debug(f"[{camera_id}] No YAW in message. Using default: {CAMERA_YAW_DEGREES}")

                        # Kafka ë©”ì‹œì§€ì—ì„œ FOV ê°’ ì¶”ì¶œ (ì—†ìœ¼ë©´ í™˜ê²½ë³€ìˆ˜ ê¸°ë³¸ê°’ ì‚¬ìš©)
                        message_horizontal_fov = fused_data.get("camera_horizontal_fov_degrees")
                        if message_horizontal_fov is not None:
                            try:
                                effective_horizontal_fov = float(message_horizontal_fov)
                                logger.debug(f"[{camera_id}] Using horizontal FOV from message: {effective_horizontal_fov}Â°")
                            except (ValueError, TypeError):
                                effective_horizontal_fov = CAMERA_HORIZONTAL_FOV_DEGREES
                                logger.warning(f"[{camera_id}] Invalid FOV in message ({message_horizontal_fov}). Using default: {CAMERA_HORIZONTAL_FOV_DEGREES}Â°")
                        else:
                            effective_horizontal_fov = CAMERA_HORIZONTAL_FOV_DEGREES
                            logger.debug(f"[{camera_id}] No FOV in message. Using default: {CAMERA_HORIZONTAL_FOV_DEGREES}Â°")


                        missing_fields = []
                        if not camera_id: missing_fields.append(f"camera_id(value:{camera_id})")
                        if not image_base64: missing_fields.append(f"image_base64(status:{'None or Empty' if not image_base64 else 'Present'})")
                        if not original_timestamp_str: missing_fields.append(f"image_timestamp_utc(value:{original_timestamp_str})")

                        if missing_fields: 
                            logger.warning(f"[{camera_id if camera_id else 'UnknownCam'}] [MISSING_FIELDS_SKIP] Skipping message. Missing/invalid fields: {'; '.join(missing_fields)}")
                            continue

                        logger.debug(f"[{camera_id}] All required fields present. Processing message.")

                        should_infer = should_process_inference(camera_id, current_process_start_time)

                        if not should_infer:
                                # ë©”ì‹œì§€ëŠ” ì†Œë¹„í–ˆì§€ë§Œ ì¸í¼ëŸ°ìŠ¤ëŠ” ìŠ¤í‚µ
                            logger.debug(f"[{camera_id}] [RATE_LIMITED] Message consumed but inference skipped (FPS limit: {INFERENCE_MAX_FPS})")
                            continue


                        img_bytes = base64.b64decode(image_base64)
                        img_np_bgr = cv2.imdecode(np.frombuffer(img_bytes, np.uint8), cv2.IMREAD_COLOR)
                        if img_np_bgr is None:
                            logger.warning(f"Failed to decode image for camera_id '{camera_id}'. Skipping.")
                            continue
                        
                        # ... (YOLO, UniDepth ì¶”ë¡  ë° ìœ„ì¹˜ ê³„ì‚° ë¡œì§ -
                        yolo_input_img = preprocess_image_for_yolo(img_np_bgr)
                        detections = run_yolo_inference(yolo_input_img)
                        logger.info(f"[{camera_id}] YOLO detected {len(detections)} objects.")
                        num_persons_detected_yolo = sum(1 for d in detections if d['class_name'] == 'person')
                        unidepth_input_img_nchw = preprocess_image_for_unidepth(img_np_bgr)
                        depth_map_hw = run_unidepth_inference(unidepth_input_img_nchw)
                        
                        person_locations = [] 
                        num_persons_located = len(person_locations)
                        if depth_map_hw is not None:
                            logger.info(f"[{camera_id}] UniDepth estimation successful. Original depth map shape: {depth_map_hw.shape}")
                            
                            # --- ğŸ’¡ ë³€ê²½/ì¶”ê°€ ì§€ì  ì‹œì‘ (ê¹Šì´ë§µ ì—…ìƒ˜í”Œë§) ---
                            depth_map_full_resolution = None # ì—…ìƒ˜í”Œë§ëœ ê¹Šì´ë§µì„ ì €ì¥í•  ë³€ìˆ˜
                            try:
                                orig_h, orig_w = img_np_bgr.shape[:2] # ì›ë³¸ ì´ë¯¸ì§€ì˜ ë†’ì´, ë„ˆë¹„
                                # cv2.resizeëŠ” (ë„ˆë¹„, ë†’ì´) ìˆœì„œë¡œ ì¸ìë¥¼ ë°›ìŠµë‹ˆë‹¤.
                                depth_map_full_resolution = cv2.resize(depth_map_hw, (orig_w, orig_h), interpolation=cv2.INTER_CUBIC) # ë˜ëŠ” cv2.INTER_LINEAR
                                logger.debug(f"[{camera_id}] Upsampled depth map to original resolution: {depth_map_full_resolution.shape}")
                            except Exception as e_resize:
                                logger.error(f"[{camera_id}] Error upsampling depth map: {e_resize}", exc_info=True)
                                # ì—…ìƒ˜í”Œë§ ì‹¤íŒ¨ ì‹œ depth_map_full_resolutionëŠ” Noneìœ¼ë¡œ ìœ ì§€ë©ë‹ˆë‹¤.
                            # --- ğŸ’¡ ë³€ê²½/ì¶”ê°€ ì§€ì  ë (ê¹Šì´ë§µ ì—…ìƒ˜í”Œë§) ---

                            # ì—…ìƒ˜í”Œë§ëœ ê¹Šì´ë§µì´ ìœ íš¨í•  ë•Œë§Œ ë‹¤ìŒ ë¡œì§ ì§„í–‰
                            if depth_map_full_resolution is not None:
                                base_uwb_x, base_uwb_y, base_uwb_tag_id = None, None, None
                                if uwb_data_from_wrapper is None:
                                    logger.debug(f"[{camera_id}] [UWB_IS_NULL] UWB data from wrapper is null.")
                                elif isinstance(uwb_data_from_wrapper, dict):
                                    base_uwb_x = uwb_data_from_wrapper.get('x_m') 
                                    base_uwb_y = uwb_data_from_wrapper.get('y_m')
                                    base_uwb_tag_id = uwb_data_from_wrapper.get('tag_id') 
                                    if base_uwb_x is None or base_uwb_y is None:
                                        logger.warning(f"[{camera_id}] [UWB_MISSING_XY] UWB data from wrapper is missing 'x_m' or 'y_m'. UWB data: {format_data_for_logging(uwb_data_from_wrapper)}") # format_data_for_logging í•¨ìˆ˜ í•„ìš”
                                else:
                                    logger.warning(f"[{camera_id}] [UWB_INVALID_TYPE] UWB data from wrapper is not a dictionary or null. Type: {type(uwb_data_from_wrapper)}. Data preview: {format_data_for_logging(uwb_data_from_wrapper)}")


                                for detection in detections:
                                    if detection['class_name'] == 'person': 
                                        box = detection['box_xyxy']
                                        xmin, ymin, xmax, ymax = box[0], box[1], box[2], box[3]
                                        cx = (xmin + xmax) / 2
                                        cy = (ymin + ymax) / 2

                                        depth_value = None # ì´ˆê¸°í™”
                                        # ğŸ’¡ ë³€ê²½/ì¶”ê°€ ì§€ì : ì—…ìƒ˜í”Œë§ëœ ê¹Šì´ë§µ(depth_map_full_resolution)ì—ì„œ ê¹Šì´ ê°’ ê°€ì ¸ì˜¤ê¸°
                                        # ì¢Œí‘œ ë²”ìœ„ ê²€ì‚¬ë„ ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°(orig_h, orig_w) ê¸°ì¤€
                                        if 0 <= int(cy) < orig_h and 0 <= int(cx) < orig_w:
                                            depth_value = depth_map_full_resolution[int(cy), int(cx)] + DEPTH_OFFSET_FACTOR 
                                        else:
                                            logger.warning(f"[{camera_id}] Person center ({cx:.2f},{cy:.2f}) out of upsampled depth map bounds ({orig_w},{orig_h}). Skipping depth for this person.")
                                        
                                        # ğŸ’¡ ë””ë²„ê·¸ ë¡œê·¸ ì¶”ê°€
                                        logger.debug(f"[{camera_id}] Upsampled depth map shape: {depth_map_full_resolution.shape}, Person center in original image: ({cx:.2f}, {cy:.2f}), Calculated depth_value: {depth_value}")

                                        calculated_x, calculated_y = None, None
                                        if base_uwb_x is not None and base_uwb_y is not None and depth_value is not None:
                                            # Yawì¶•ì„ ê³ ë ¤í•œ ìœ„ì¹˜ ê³„ì‚° (ë©”ì‹œì§€ì˜ YAW ê°’ ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ ê¸°ë³¸ê°’ ì‚¬ìš©)
                                            calculated_x, calculated_y, angle_from_center = calculate_position_with_yaw_and_fov(
                                                        base_uwb_x, base_uwb_y, depth_value, cx, cy, orig_w, orig_h, 
                                                        effective_yaw_degrees, effective_horizontal_fov
                                            )
                                            
                                            person_locations.append({
                                                "person_id": f"person_{len(person_locations)+1}", 
                                                "box_xyxy": [round(coord, 2) for coord in box],
                                                "confidence": round(detection['confidence'], 4),
                                                "center_image_coord": (round(cx,2), round(cy,2)),
                                                "depth_value_at_center": round(depth_value,3) if depth_value is not None else None,
                                                "estimated_world_x": round(calculated_x,3) if calculated_x is not None else None,
                                                "estimated_world_y": round(calculated_y,3) if calculated_y is not None else None,
                                                "base_uwb_used": {"tag_id": base_uwb_tag_id, "x": base_uwb_x, "y": base_uwb_y},
                                                "camera_yaw_degrees": effective_yaw_degrees,  # ì‹¤ì œ ì‚¬ìš©ëœ YAW ê°’
                                                "relative_x_in_image": round((cx - orig_w / 2) / (orig_w / 2), 3)
                                            })
                                        else:
                                            logger.debug(f"[{camera_id}] [LOC_CALC_SKIP] Skipping location calculation for person (box: {[round(c,1) for c in box]}). UWB_X: {base_uwb_x}, UWB_Y: {base_uwb_y}, Depth: {depth_value}")
                            else: # depth_map_full_resolution is None (ì—…ìƒ˜í”Œë§ ì‹¤íŒ¨ ì‹œ)
                                logger.warning(f"[{camera_id}] Depth map upsampling failed. Cannot calculate person locations.")
                        else: # depth_map_hw is None (UniDepth ì¶”ë¡  ì‹¤íŒ¨ ë˜ëŠ” ëª¨ë¸ ë¯¸ë¡œë“œ)
                            logger.warning(f"[{camera_id}] UniDepth estimation failed or model not loaded. Cannot calculate person locations.")

                        # --- ìµœì¢… ì¶œë ¥ ë©”ì‹œì§€ ìƒì„± ---
                        inference_output = {
                            "camera_id": camera_id,
                            "image_timestamp_utc": original_timestamp_str,
                            "timestamp_inference_utc": datetime.now(timezone.utc).isoformat(),
                            "uwb_data_received": uwb_data_from_wrapper, 
                            "detections_yolo": detections, 
                            "person_locations_estimated": person_locations 
                        }
                        
                        log_summary_keys = ["camera_id", "image_timestamp_utc", "detections_yolo", "person_locations_estimated"]
                        log_output_summary = {
                            k: (f"{len(v)} items" if isinstance(v, list) else v) 
                            for k, v in inference_output.items() if k in log_summary_keys
                        }
                        log_output_summary["processing_time_ms"] = round((time.monotonic() - current_process_start_time) * 1000, 2)
                        logger.info(f"[{camera_id}] Inference Complete. Output Summary: {json.dumps(log_output_summary)}")

                        log_output_summary["yolo_total_detections"] = len(detections)
                        log_output_summary["yolo_persons_detected"] = num_persons_detected_yolo
                        log_output_summary["persons_located_final"] = num_persons_located
                        log_output_summary["unidepth_map_shape_raw"] = depth_map_hw.shape if depth_map_hw is not None else "N/A"

                        log_output_summary["processing_time_ms"] = round((time.monotonic() - current_process_start_time) * 1000, 2)
                        logger.info(f"[{camera_id}] Inference Complete. Output Summary: {json.dumps(log_output_summary)}")


                        if kafka_producer_instance:
                            try:
                                future = kafka_producer_instance.send(OUTPUT_TOPIC_INFERENCE, value=inference_output)
                                future.get(timeout=5) 
                                logger.debug(f"[{camera_id}] Successfully sent inference result to Kafka topic '{OUTPUT_TOPIC_INFERENCE}'.")
                            except KafkaError as ke_prod:
                                logger.error(f"[{camera_id}] Failed to send message to Kafka topic '{OUTPUT_TOPIC_INFERENCE}': {ke_prod}", exc_info=True)
                            except Exception as e_send:
                                logger.error(f"[{camera_id}] An unexpected error occurred while sending message to Kafka: {e_send}", exc_info=True)
                        else:
                            logger.warning(f"[{camera_id}] Kafka producer is not available. Skipping message sending for output topic {OUTPUT_TOPIC_INFERENCE}.")



                    except Exception as e_proc:
                        logger.error(f"Error processing message for camera_id '{camera_id if 'camera_id' in locals() else 'unknown'}': {e_proc}", exc_info=True)
                
                # consumer_timeout_msê°€ ë§Œë£Œë˜ë©´ for ë£¨í”„ê°€ ìì—°ìŠ¤ëŸ½ê²Œ ì¢…ë£Œë˜ê³ ,
                # while ë£¨í”„ì˜ ë‹¤ìŒ ë°˜ë³µìœ¼ë¡œ ë„˜ì–´ê° (stop_event ì²´í¬)
                # ì—¬ê¸°ì„œ ë³„ë„ì˜ time.sleepì€ í•„ìš” ì—†ìŒ.

            except KafkaError as ke: # Kafka ì»¨ìŠˆë¨¸ ìì²´ì˜ ì˜¤ë¥˜ (ì˜ˆ: ì—°ê²° ë¬¸ì œ)
                logger.error(f"KafkaError in consumer polling loop: {ke}", exc_info=True)
                if not stop_event.is_set():
                    time.sleep(5) # ì ì‹œ ëŒ€ê¸° í›„ ì¬ì‹œë„
            except Exception as e_loop: # ë©”ì‹œì§€ í´ë§/ì²˜ë¦¬ ë£¨í”„ì˜ ê¸°íƒ€ ì˜ˆì™¸
                logger.error(f"Unexpected error in consumer polling loop: {e_loop}", exc_info=True)
                if not stop_event.is_set():
                    time.sleep(5)
        # while ë£¨í”„ ì¢…ë£Œ (stop_event ì„¤ì •ë¨)
    finally: # Main try blockì— ëŒ€í•œ finally
        if consumer: 
            logger.info("Closing Kafka consumer.")
            consumer.close()
        if kafka_producer_instance:
            logger.info("Flushing and closing Kafka producer.")
            kafka_producer_instance.flush(timeout=10) 
            kafka_producer_instance.close(timeout=10)
    
    logger.info("Message consumption loop_thread stopped.")


# --- ì„œë¹„ìŠ¤ ì¢…ë£Œ ì²˜ë¦¬ ---
def shutdown_handler(signum, frame):
    logger.info(f"Signal {signal.Signals(signum).name} received. Initiating graceful shutdown...")
    stop_event.set()

# --- ë©”ì¸ ì‹¤í–‰ ---
if __name__ == "__main__":
    signal.signal(signal.SIGINT, shutdown_handler)
    signal.signal(signal.SIGTERM, shutdown_handler)

    logger.info("Starting Falcon Inference Service...")
    
    load_yolo_model()
    load_unidepth_model()

    if yolo_model is None and unidepth_session is None:
        logger.fatal("Neither YOLO nor UniDepth models could be loaded. Exiting service.")
        import sys 
        sys.exit(1)
    elif yolo_model is None:
        logger.warning("YOLO model failed to load. Service will run without object detection.")
    elif unidepth_session is None:
        logger.warning("UniDepth model failed to load. Service will run without depth estimation.")

    consumer_thread = threading.Thread(target=consume_messages, name="KafkaConsumerThread", daemon=True)
    consumer_thread.start()

    try:
        while not stop_event.is_set():
            if not consumer_thread.is_alive() and not stop_event.is_set():
                logger.error("KafkaConsumerThread died unexpectedly! Initiating shutdown.")
                stop_event.set() 
                break
            stop_event.wait(timeout=1.0) 
    except KeyboardInterrupt: 
        logger.info("KeyboardInterrupt in main thread. Initiating shutdown...")
        stop_event.set()
    
    logger.info("Waiting for consumer thread to finish...")
    if consumer_thread.is_alive():
        consumer_thread.join(timeout=10) 
        if consumer_thread.is_alive():
            logger.warning("Consumer thread did not stop gracefully.")

    logger.info("Falcon Inference Service stopped.")